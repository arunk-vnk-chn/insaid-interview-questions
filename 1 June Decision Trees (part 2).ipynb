{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 June - Decision Trees (part 2).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunk-vnk-chn/insaid-interview-questions/blob/master/1%20June%20Decision%20Trees%20(part%202).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9YduuPg141j",
        "colab_type": "text"
      },
      "source": [
        "# 1 June - Decision Trees (part 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL5d4rwH2D8k",
        "colab_type": "text"
      },
      "source": [
        "**1. What do homogenous and heterogenous mean in the context of decision tree / entropy?**\n",
        "\n",
        "* A homogenous dataset is one in which the most of the features/classes have same values, while a heterogeneous dataset is one in which they have high variety.\n",
        "\n",
        "* Entropy will be low (close to 0) for a homogeneous dataset and high (close to 1) for a heterogenous dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGGhPUk86hL1",
        "colab_type": "text"
      },
      "source": [
        "**2. What is the entropy of a sample?**\n",
        "\n",
        "* Entryopy measures the extent of chaoes or heterogenity of the sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o1C241q7nF1",
        "colab_type": "text"
      },
      "source": [
        "**3. How is entropy calculated?**\n",
        "\n",
        "* Entropy of entire sample = - sum ( p(i) * log p(i) ), for all i categories of the class (Y variable)\n",
        "\n",
        "* The log should be of base 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDMU-9Lm7X_L",
        "colab_type": "text"
      },
      "source": [
        "**4. Which algorithms are better for binary classification and which are better for multi-class classification?**\n",
        "\n",
        "* Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gI1Jfzo7hYj",
        "colab_type": "text"
      },
      "source": [
        "**5. How do we convert a multi-class classification problem into a binary classification problem?  What is \"1 vs all\"?**\n",
        "\n",
        "* The 1 vs all strategy involves training a single classifier per class, with the samples of that class as positive samples and all other samples as negatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQu2ZuBY8eD2",
        "colab_type": "text"
      },
      "source": [
        "**6. In decision tree modeling, how do you decide which feature to start with, and which features to pick next?**\n",
        "\n",
        "* It depends on the algorithm used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4y5ZfBl8_uj",
        "colab_type": "text"
      },
      "source": [
        "**7. What is the base form of the logarithm used in the entropy formula?**\n",
        "\n",
        "* 2 is the base of log to be used. It ensures entropy is between 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5Arw0K091tr",
        "colab_type": "text"
      },
      "source": [
        "**8. How will the entropy of two different class values having exactly inverted probabilities compare?**\n",
        "\n",
        "* Equal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLYWGPD6-O-x",
        "colab_type": "text"
      },
      "source": [
        "**9. What to do in case of missing values in training set for decision tree modeling?**\n",
        "\n",
        "* Rows having missing values need to be removed from training set before building a decision tree model. However missing values should be retained in the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpAtJl_KBJp8",
        "colab_type": "text"
      },
      "source": [
        "**10. How many different entropy values can be calculated for a feature having two categories? What about n categories in general where n > 2?**\n",
        "\n",
        "* **1** - for 2 categories\n",
        "* **n** - For n categories, where n > 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRWMXJGg_shD",
        "colab_type": "text"
      },
      "source": [
        "**11. What is information gain?**\n",
        "\n",
        "* Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_6phLOFBjE-",
        "colab_type": "text"
      },
      "source": [
        "**12. How does information gain imply in decision tree for the ID3 algorithm?**\n",
        "\n",
        "* Decision tree is about finding the path that gives highest information gain, i.e., having homogeneous branches.\n",
        "\n",
        "* We take the feature having highest chaos (highest entropy) but the branches below it will have highest homogenity.\n",
        "\n",
        "* The feature having highest information gain is selected as the root node.\n",
        "\n",
        "* Then for each possible category of the root node feature, the feature (from the remaining features) having highest information gain is selected as a decision node, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqAkNAjJH2F5",
        "colab_type": "text"
      },
      "source": [
        "**13. Is decision tree a good model if the feature values change regularly?**\n",
        "\n",
        "* No, as it would have to be rebuilt again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpUivzQdL9D8",
        "colab_type": "text"
      },
      "source": [
        "**13. When should Gini index be used and when should information gain be used?**\n",
        "\n",
        "* Gini works well only for categorical variables. Information gain can be used for both categorical as well as numerical variables.\n",
        "\n",
        "* If only categorical variables, either would work fine and give largely similar results\n",
        "\n",
        "* If data is highly chaotic (high categorization), Gini index is better as it accomodates the smaller fractions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrnL2PR9MiWO",
        "colab_type": "text"
      },
      "source": [
        "**13. Which gini index should be used?**\n",
        "\n",
        "* Lowest gini index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEtCgQ8SP7uJ",
        "colab_type": "text"
      },
      "source": [
        "**13. How are numerical variables handled in decision trees?**\n",
        "\n",
        "* They are algorithmically binned into discrete categories before using in decision trees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unbtgnErRUdB",
        "colab_type": "text"
      },
      "source": [
        "Underfitting and overfitting are directions in machine learning.\n",
        "\n",
        "They are not absolute values.\n",
        "\n",
        "Optimal is the general best choice.\n",
        "\n",
        "However if data doesn't cchange frequently, going in the direction of overfitting is optimal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DoxLrHjURDQ",
        "colab_type": "text"
      },
      "source": [
        "**15. What is bias, variance and bias-variance tradeoff?**\n",
        "\n",
        "bias and variance are referential terms. These are relative to different models.\n",
        "\n",
        "It is not possible to comment on bias and variance from just a single model.\n",
        "\n",
        "If confusion, pick simplest (more robust)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_82Uuc2beJu",
        "colab_type": "text"
      },
      "source": [
        "**How do we handle big data?**\n",
        "\n",
        "* Spark\n",
        "\n",
        "* If Spark not available, then Dask can be used natively "
      ]
    }
  ]
}